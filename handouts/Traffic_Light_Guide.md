# Traffic Light Guide â€” When to Trust AI Output

**Know when to trust, verify, or own the decision.**

---

## ðŸŸ¢ Green Light â€” Trust the Output

*Low stakes, easy to spot errors, your domain knowledge covers it.*

| Task | Why It's Green |
|------|---------------|
| Brainstorming & ideation | Quantity matters, you pick quality |
| First drafts of emails | You'll review before sending |
| Summarizing your own documents | You know the content, can spot errors |
| Meeting agenda creation | Low stakes, easy to edit |
| Reformatting & restructuring text | Mechanical task, obvious if wrong |
| Rephrasing for tone/audience | You judge the tone yourself |
| Data formatting (CSV â†’ table) | Verifiable at a glance |
| Template creation | You customize before using |
| Proofreading suggestions | You accept/reject each change |
| Learning new topics | You're exploring, not deciding |

**Green rule:** If you can spot a mistake in 5 seconds, it's green light.

---

## ðŸŸ¡ Yellow Light â€” Verify Key Points

*Important but checkable. Use AI output as a starting point, then validate.*

| Task | What to Verify |
|------|---------------|
| Research & fact-finding | Cross-check key claims with sources |
| Data analysis & trend spotting | Validate numbers against raw data |
| Technical content creation | Have a subject expert review |
| Financial calculations | Re-run critical formulas manually |
| Competitive analysis | Verify company data is current |
| Market research summaries | Check dates and sources |
| Code review suggestions | Test before deploying |
| Process improvement recommendations | Validate against your operations |
| Training material creation | Subject expert sign-off |
| Customer insight analysis | Compare against actual customer data |

**Yellow rule:** Trust the structure, verify the facts. Check numbers, dates, and claims.

---

## ðŸ”´ Red Light â€” Human Owns It

*High stakes, specialized knowledge, or irreversible consequences. AI assists, you decide.*

| Task | Why It's Red |
|------|-------------|
| Legal advice & contract decisions | Requires licensed professional |
| Medical or health recommendations | Liability and safety risk |
| Final financial decisions (investments, loans) | Fiduciary responsibility |
| Handling personal/sensitive data (SSN, salary) | Privacy and compliance risk |
| Official company statements (press, legal) | Reputational and legal exposure |
| Regulatory compliance determinations | Requires certified expertise |
| Hiring/firing decisions | Legal liability, human judgment |
| Security architecture decisions | Risk of breach if wrong |
| Mergers, acquisitions, strategic commitments | Irreversible, high-stakes |
| Anything requiring professional certification | AI has no license or liability |

**Red rule:** If getting it wrong has legal, financial, or safety consequences â†’ human decides, AI assists.

---

## Decision Framework

```
Is the task low-stakes and easy to verify?
  â†’ YES â†’ ðŸŸ¢ Green: Trust it
  â†’ NO  â†’ Could you verify the key facts?
             â†’ YES â†’ ðŸŸ¡ Yellow: Use it, then check
             â†’ NO  â†’ ðŸ”´ Red: Human decides, AI assists
```

**When in doubt, treat it as Yellow.** Verify key points, then proceed.

---

## The 19% Rule

A BCG study found teams **lost 19% accuracy** when they used AI on tasks outside its capability frontier (Red Light tasks treated as Green). Knowing which color your task is prevents this drop.

**The skill isn't using AI â€” it's knowing WHEN to use AI.**

---

*Â© 2026 AIA Copilot â€” Traffic Light Guide: When to Trust AI Output*
